\documentclass[runningheads]{llncs} % template "Lecture notes for computer science"
\usepackage[spanish]{babel} % para el texto en espanhol
\usepackage{graphicx} % para incluir imagenes, graficos, etc.
\graphicspath{{images/}} % ruta a la carpeta de imagenes
\usepackage{hyperref} % para los hipervinculos
\usepackage{xurl} % para el line breaker de los url
\usepackage{xcolor} % para definir colores custom
\hypersetup{ % configuracion de los hiper vinculos
    colorlinks=true,
    linkcolor=black,
    filecolor=black,      
    urlcolor=blue,
    citecolor=black, % ver si poner en blue o dejar asi
    pdftitle={Redes neuronales},
    pdfpagemode=FullScreen,
}
\usepackage[T1]{fontenc} % para la codificacion de la fuente.
\usepackage[backend=biber,style=numeric]{biblatex} % para la bibliografia.
\addbibresource{bibliografia.bib} % incluir el .bib
\setcounter{biburlnumpenalty}{9000} % Para el line breaker en URL con numeros (que tambien afecta a la bibliografia)
\setcounter{biburllcpenalty}{9000} % Para el line breaker en URL con letras minuculas (que tambien afecta a la bibliografia)
\setcounter{biburlucpenalty}{9000} % Para el line breaker en URL con letras mayusculas (que tambien afecta a la bibliografia)
\usepackage{csquotes} % para que los textos citados esten con tipografia de acuerdo con las reglas de csquotes
\usepackage{amsmath}

\begin{document}

% =================================================================================
% PORTADA
% =================================================================================
\title{Redes neuronales y sus aplicaciones recientes}

%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Alain Vega \\ \email{alainjosevz@gmail.com}}
%
\authorrunning{Alain Vega}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Universidad Catolica "Nuestra señora de la Asuncion" \\ 
Facultad de ciencias y tecnologia \\
Departamento de electronica e informatica \\
\url{https://www.universidadcatolica.edu.py/} }
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Una de las tendencias ultimamente son las redes neuronales. En este documento
se muestran conceptos claves sobre este modelo y una significativa variedad
de ejemplos sobre aplicaciones recientes del mismo.

\keywords{Redes neuronales \and Inteligencia artificial \and Machine learning
\and Deep learning \and AI \and ML \and NN \and ANN \and SNN \and RNN 
\and CNN \and DL}
\end{abstract}
% =================================================================================
% CONTENIDO
% =================================================================================
\section{Introduccion}
Si hace unos años, nos hubieran dicho que una máquina sería capaz de aprender 
por sí sola y tomar decisiones basadas en esa experiencia, ¿te lo habrías creído? 
¿Y si además te hubieran dicho que un conjunto de algoritmos serían capaces de
hacer funciones consideradas \textquotedblleft{humanas}\textquotedblright{}
como crear arte o componer melodías únicas? \cite{int1}

Todo esto es ya una realidad, por ello ultimamente la Inteligencia artificial (AI) 
esta en boca de todos, pero es gracias a las \textbf{redes neuronales} (NN)
que todo esto es posible. 

Estas redes alcanzan metas bastante impresionantes y que cada vez se acercan 
más a esa idea original de reproducir el funcionamiento del cerebro humano 
en una computadora. 

Ahora bien, ¿en qué consisten estos modelos? ¿Cómo puede imitar un computadora 
el proceso de aprendizaje y acabar desarrollando una
\textquotedblleft{cosa}\textquotedblright{} que funciona? \cite{int2}
\section{¿Que es una red neuronal?}
Una red neuronal, tambien conocida como red neuronal artificial (ANN)
o red neuronal simulada (SNN), es un modelo de \textit{machine learning} (ML)
el cual constituye el eje de los algoritmos de \textit{deep learning} (DL) 

Su nombre y estructura se inspiran en el cerebro humano, 
e imitan la forma en la que las neuronas biológicas se señalan entre sí.

Las redes neuronales artificiales (ANN) están formadas por capas de nodos, 
que contienen una capa de entrada, una o varias capas ocultas y una capa de salida.
\cite{def-ibm1}

Donde cada nodo se conoce como una neurona artificial, esta se conecta a 
otra neurona (nodo) la capa hace referencia a conjunto de nodos (neuronas).

\begin{figure}
    \centering
    \includegraphics[scale=0.6]{red_neuronal_artificial.png}
    \caption{Ejemplo de una red neuronal artificial (ANN) \cite{int1}}
    \label{fig:red_neuronal_artificial}
\end{figure}

En la figura \ref{fig:red_neuronal_artificial} se muestra un ejemplo,
aqui la capa de la izquierda es la capa de entrada (la que esta
conectada con el \textquotedblleft{mundo}\textquotedblright{} exterior y se alimenta de el)
las capas 2 y 3 son capas ocultas que ayudan al procesamiento
de la tarea y por ultimo la capa 4 es la de salida, la cual
envia sus resultados al \textquotedblleft{mundo}\textquotedblright{} exterior

\section{Estructura basica de una red neuronal}
\subsection{Analogia con el cerebro}
La neurona es la unidad fundamental del sistema nervioso y en particular 
del cerebro. Cada neurona es una simple unidad procesadora que recibe y combina 
señales desde y hacia otras neuronas. 
Si la combinación de entradas es suficientemente fuerte la salida de la neurona
se activa. \cite{libro-def}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{neurona_real.png}
    \caption{Componentes de una reurona real \cite{img-neurona_real}}
    \label{fig:neurona_real}
\end{figure}

El cerebro consiste en uno o varios billones de neuronas densamente 
interconectadas. Apoyandonos en la figura \ref{fig:neurona_real}.
El axón (salida) de la neurona se ramifica y está conectada a las dendritas (entradas) 
de otras neuronas a través de uniones llamadas sinapsis.
La eficacia de la sinpasis es modificable durante el proceso de 
aprendizaje de la red. \cite{libro-def}

\subsection{Redes neuronales artificiales (ANN)}
En las Redes Neuronales Artificiales, ANN, la unidad análoga a la neurona biológica es
el elemento procesador, PE (\textit{Process Element}). Un elemento procesador tiene varias
entradas y las combina, normalmente con una suma básica. 
\footnote[1]{Existen mas formas de combinar las entradas de la neurona 
que la sumatoria, como por ejemplo con un productorio: \(\Pi_{i}{w_{i}*x_{i}}\)
o aplicando la funcion maximo elemento: \(\max_{i}{w_{i}*x_{i}}\) \cite{tesis-matich}}.
La suma de las entradas es
modificada por una función de transferencia y el valor de la salida de esta función de
transferencia se pasa directamente a la salida del elemento procesador.
\footnote[2]{En lugar de pasar el valor de la funcion de transferencia
directamente a la salida (funcion de salida = funcion identidad), 
se puede pasar por otra funcion, \textbf{la funcion de salida} 
la cual pueder ser una funcion binaria \cite{tesis-matich} \\
\(B(x)=1\) si \(x>=umbral\), \\
\(B(x)=0\) caso contario}

La salida del PE se puede conectar a las entradas de otras neuronas artificiales (PE)
mediante conexiones ponderadas correspondientes a la eficacia de la sinapsis de las
conexiones neuronales. \cite{libro-def}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{neurona_artificial2.png}
    \caption{Diagrama de una neurona artificial con conceptos de una neurona real \cite{img-neurona_artificial2}}
    \label{fig:neurona_artificial}
\end{figure}

La Figura \ref{fig:neurona_artificial} muestra una neurona artificial con conceptos
de una neurona real.
La dendrita se representa como un enlace de entrada a la neurona.

La sinapsis se representa como la union/fusion de un terminal del axon de una neurona
con una dendrita de otra neurona. 

En el cuerpo celular ocurren varias cosas, la primera es que gracias a sinapsis las
entradas disponibles de cada una de las neuronas de la capa anterior llegan como el 
producto \(x_{i}*w_{i}\), donde \(x_{i}\) es el resultado de una neurona 
\textquotedblleft{anterior}\textquotedblright{} y \(w_{i}\) es el peso 
\textquotedblleft{conectarse}\textquotedblright{} a la dendrita de nuestra neurona.
La segunda es la sumatoria de cada entradas \(x_{i}*w_{i}\) y sumarle
\(b\) que representa el bias/sesgo/umbral (el cual nos permite mover la funcion
de activacion de manera horizontal).
Por ulitmo toda la sumatoria del paso dos, se pasa a la funcion de activacion \(f\)
esta puede lineal o no lineal, existen una amplia variedad de funciones de activacion.

Finalmente transmite el resultado \(y = f(\sum_{i=1}^{n}{x_{i}*w_{i}} + b)\)
suponiendo \textit{n} entradas

\section{Funcion de activacion}
La funcion de activacion se encarga de decidir cuando una neurona artificial debe activarse
o no. Esto significa que dicha funcion decide cuando la entrada a la neurona artificial
es importante o no para la red. \cite{fun-activacion}

Su rol es derivar la salida de la neurona artificial, dado un conjunto de valores de la entrada
para alimentar a otras neuronas artificiales. \cite{fun-activacion}

Existen muchas funciones de activacion, se pueden clasificar en tres grupos.
\subsection{Clases de funciones de activacion}

\subsubsection{Funciones de paso binario}
Necesita de un valor umbral \(\xi\) que decide cuando la neurona artificial debe activarse o no.
\cite{fun-activacion}

\[
    B(x) =
    \left \{
        \begin{aligned}
        0, \ \ & \text{si } x < \xi  \\
        1, \ \ & \text{si } x \geq \xi
        \end{aligned}
    \right .
\]


% Por motivos de simplicidad desde este punto hasta el final del documento, 
% cada vez que aparezca la frase \textquotedblleft{red neuronal}\textquotedblright{} y 
% \textquotedblleft{neuronal}\textquotedblright{}
% se hace referencia a la \textquotedblleft{red neuronal artificial}\textquotedblright{} y 
% a la \textquotedblleft{neuronal artificial}\textquotedblright{} respectivamente,
% se precisara cuando se hable de una neurona real.

\subsubsection{Funciones de activacion lineales}
Tambien conocida como \textquotedblleft{}sin activacion\textquotedblright{} 
donde la activacion es proporcional a la entrada. \cite{fun-activacion2} \\
Se utilizan en la capa de salida para problemas de regresion lineal. \cite{fun-activacion}

\[ f(x)=mx+b \]

\subsubsection{Funciones de activacion no lineales}
Son las mas utilizadas ya que facilita que el modelo generice o se adapte con una 
variedad de datos y diferencie entre los resultados. \cite{fun-activacion2}

Las principales son: 
\begin{itemize}
    \item{\textbf{Sigmoide o logistica}: utlizada en la capa de salida
    para problemas de clasificacion binaria (clasificar en 2 grupos) y problemas
    de clasificacion multietiqueta o multi-objetivo (la salida puede estar 
    en mas de un grupo). \cite{fun-activacion}
    \[\sigma(x) = \frac{1}{1-e^{-x}}\] } 
    \item{\textbf{Tangente hiperbolico}: utilizada en las capas ocultas 
    de una red neuronal recurrent (RNN). \cite{fun-activacion}
    \[\tanh(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}\]}
    \item{\textbf{ReLU (\textit{Rectified Linear Unit})}: utilizada en las capas
    ocultas de una red neuronal convolucional (CNN). \cite{fun-activacion}
    \[ReLU(x) = max(0,x)\]} 
    \item{\textbf{Softmax}: utilizada en la capa de salida para problemas
    de multi-clasificacion (clasificar en mas de 2 grupos). \cite{fun-activacion}
    \[ s(x_{i}) = \frac{e^{x_{i}}}{\sum_{j=1}^{n}{e^{x_{j}}}} \]}\\
    La funcion Softmax convierte el vector de \textit{K} entradas a un vector 
    de \textit{K} salidas tal que la suma las salidas es igual a 1,
    entonces la salida se puede interpretar como una distribucion de probabilidades.
    \cite{fun-softmax}
\end{itemize}

\subsection{Tipos de Redes neuronales}
\subsection{AI vs ML vs NN vs DL}
\section{Conocimiento}
\subsection{¿Como aprenden estas redes?}
\subsubsection{Propagacion hacia atras}
\subsection{¿Representa como aprendemos los humanos?}
Si bien las redes neuronales estan inspiradas en el cerebro humano, ¿esto significa 
que estas redes pueden verse como un cerebro humano simulado?, estudios recientes sugieren 
que podría no ser así. Un equipo del MIT examinó recientemente más de 11.000 redes neuronales 
y descubrió que sólo exhibían las características de procesamiento celular del pensamiento 
humano cuando estaban entrenadas para hacerlo. 

Sin esas restricciones, pocas redes desarrollaron la actividad similar a la de las células 
que puede usarse para predecir la funcionalidad cerebral real, que evoluciona naturalmente 
sin condiciones previas. \cite{NNvsANN}

\subsubsection{Diferencias de aprendizaje} 
Otra diferencia clave entre las redes neuronales y los cerebros vivos es la forma 
en que aprenden. Según Maxim Bazhenov, Ph.D. y profesor de medicina en la 
Facultad de Medicina de la Universidad de California en San Diego, 
las ANN sobrescriben datos antiguos a medida que se reciben nuevos datos mientras 
el cerebro se involucra en un aprendizaje continuo e incorpora nuevos datos para lograr 
mayores niveles de comprensión. \cite{NNvsANN}

\section{Aplicaciones}
\subsection{ChatGPT}
Es una de las aplicaciones recientes mas reconocidas, ya casi no necesita presentacion.
Su exito fue tan grande que empresas como Google o Microsoft apresuraron sus proyectos
\textit{Bard} y \textit{Bing} respectivamente.

ChatGPT (\textit{Generative Pre-trained Transformer}) es un procesador del lenguaje natural
desarrollada por OpenAI, es un modelo hermano de InstructGPT, que esta capacitado
para seguir una instruccion en un mensaje y proporcionar una respuesta detallada.
\cite{ej-chatgpt}
\subsubsection{¿Como funciona?}
Se entrena el modelo utilizando \textit{Reinforcement Learning from Human Feedback}, 
(RLHF) es decir el aprendizaje por refuerzo a partir de la retroalimentacion humana,
similar a su hermano InstructGPT pero con ligeras diferencias en la configuracion de
recopilacion de datos. \cite{ej-chatgpt}

Se entrena un modelo inicial mediante ajustes supervisados: los entrenadores humanos
de la AI proporcionan conversaciones en las que juegan de ambos lados: el usuario
y un asistente de AI. Se les da a los capacitadores acceso a sugerencias escritas
por modelos para ayudarlos a redactar sus respuestas. 
Se mezcla este nuevo conjunto de datos de diálogo con el conjunto de datos de InstructGPT, 
el cual transforman en un formato de diálogo. \cite{ej-chatgpt}

Para crear un modelo de recompensa para el aprendizaje por refuerzo, 
se necesita recopilar datos comparativos, que consisten en dos o más respuestas 
del modelo clasificadas por calidad. Para recopilar estos datos, se toman conversaciones 
que los entrenadores de IA tuvieron con el chatbot. Seleccionan al azar un mensaje 
escrito por un modelo, prueban varias alternativas de finalización y se pide a los 
entrenadores de IA que las clasifiquen. Usando estos modelos de recompensa, 
ajustan el modelo usando la Optimización de Política Proximal (la cual es
una nueva clase de algoritmos de aprendizaje por refuerzo, que funcionan de manera
comparable o mejor que los enfoques actuales y, al mismo tiempo, son mucho mas
simples de implementar y ajustar \cite{def-PPO})

Realizan varias iteraciones de este proceso. \cite{ej-chatgpt}

\begin{figure}
    \centering
    \includegraphics[scale=0.4]{ChatGPT_Diagram.jpg}
    \caption{Diagrama del metodo de entrenamiento
    para ChatGPT \cite{ej-chatgpt}}
    \label{fig:chatgpt-diagrama}
\end{figure}

Aqui van unos ejemplos de consultas a ChatGPT, el lector puede probarlo por
el mismo en el siguiente enlace: 

\begin{figure}
    \centering
    \includegraphics[scale=0.55]{ej1-chatgpt.png}
    \caption{Ejemplo de consulta sobre corrector ortografico de español
    para LaTeX}
    \label{fig:chatgpt-ej1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.55]{ej2-chatgpt.png}
    \caption{Ejemplo de consulta donde se le pide que enseñe el 
    lenguaje de programacion Go}
    \label{fig:chatgpt-ej2}
\end{figure}

\subsection{DALL-E}
De los mismos creadores de ChatGPT (OpenAI) DALL-E es otro caso de exito que muy
probablemente el lector ya lo conozca. Se trata  de una de las AI que comenzaron
esta revolucion de generar imagenes, junto a otras como \textit{Stable Diffusion}
y \textit{MidJourney}. \cite{dalle-xtaka}

DALL-E es un sistema de AI que tiene la capacidad de crear imagenes realistas y arte
dada una descripcion en lenguaje natural. \cite{ej-dalle}

\subsubsection{¿Como funciona?}
DALL-E fue creada al entrenar una red neuronal con imagenes y su descripcion en lenguaje
natural, a traves del DL no solo comprende objetos individuales sino que tambien aprende 
de las relaciones entre objetos. \cite{ej-dalle}

DALL-E utiliza lo que se llama un modelo de difusión, que son esos sistemas 
de inteligencia artificial capaces de crear imágenes de la nada. 
En este proceso de creación, aprende de las estructuras latentes de los datos 
para entrenarse para eliminar el ruido gaussiano de imágenes borrosas, 
que son esas pequeñas distorsiones que pueden generarse en este tipo de AI. 
\cite{dalle-xtaka}

Su proceso de creación se puede resumir en tres pasos. 
Primero, codifica y entiende el texto que le has escrito en el prompt 
distingue los diferentes rasgos, características y estilos que has pedido que dibuje.
Luego, DALL-E crea información de imagen a partir de esta petición, y finalmente 
utiliza un decodificador que pinta la imagen partiendo de ese texto. \cite{dalle-xtaka}

Aqui van unos ejemplos de lo que se puede hacer con DALL-E:

\begin{figure}
    \centering
    \includegraphics[scale=0.19]{ej1-dalle.jpg}
    \caption{Ejemplo de generacion de imagen: un astronauta montando un
    caballo con estilo fotorealistico \cite{ej-dalle}}
    \label{fig:dalle-ej1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.15]{ej2.1-dalle.jpg}
    \includegraphics[scale=0.2]{ej2.2-dalle.jpg}
    \caption{Ejemplo de \textit{Outpainting}: agregar contexto a una
    imagen \cite{ej-dalle}}
    \label{fig:dalle-ej2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.25]{ej3.1-dalle.jpg}
    \includegraphics[scale=0.25]{ej3.2-dalle.jpg}
    \caption{Ejemplo de \textit{Inpainting} entrada: agrega un flamenco
    al lado de la piscina \cite{ej-dalle}}
    \label{fig:dalle-ej3}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.25]{ej4.1-dalle_1.jpg}
    \includegraphics[scale=0.25]{ej4.2-dalle_1.jpg}
    \caption{Ejemplo de Variaciones de una imagen \cite{ej-dalle}}
    \label{fig:dalle-ej4}
\end{figure}

\subsection{DeepFake}
La tecnologia \textit{deepfake} es una tecnica que manipula imagenes o videos por medio del 
\textit{deep learning}. El resultado es una imagen o video muy realista de un evento que nunca ocurrio.
\cite{ej-deepfake2}

Un \textit{deepfake} es una imagen o un vídeo falsificado digitalmente de una persona 
que la hace parecer otra persona. Es el siguiente nivel de creación de contenido falso 
que aprovecha la inteligencia artificial. \cite{ej-deepfake2}

La gente empezó a tomar conciencia de la tecnología deepfake cuando un usuario de Reddit 
llamado \textquotedblleft{}Deepfakes\textquotedblright{} publicó que había desarrollado
un algoritmo de ML que podía transponer rostros de celebridades sin problemas
a vídeos de contenido para adultos. \cite{ej-deepfake2}
 
\subsubsection{¿Como funciona?}
Un vídeo deepfake explota dos modelos de \textit{machine learning}. 
Un modelo crea falsificaciones a partir de un conjunto de datos de vídeos de muestra, 
mientras que el otro intenta detectar si el vídeo es realmente un fraude. 
Cuando el segundo modelo ya no puede decir si el vídeo es falso, 
el deepfake probablemente también sea lo suficientemente creíble para un 
espectador humano. 
Esta técnica se llama
\textquotedblleft{}red generativa adversarial\textquotedblright{} (GAN). \cite{ej-deepfake2}

Aqui van unos ejemplos:
\begin{figure}
    \centering
    \includegraphics[scale=0.6]{ej1-deepfake.png}
    \caption{Ejemplo de deepfake \cite{ej-deepfake3}}
    \label{fig:deepfake-ej1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.6]{ej2-deepfake.png}
    \caption{Ejemplo de deepfake \cite{ej-deepfake3}}
    \label{fig:deepfake-ej2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.4]{ej3-deepfake.jpeg}
    \caption{Ejemplo de deepfake \cite{img-deepfake}}
    \label{fig:deepfake-ej3}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.4]{ej4-deepfake.jpg}
    \caption{Ejemplo de deepfake \cite{ej-deepfake1}}
    \label{fig:deepfake-ej4}
\end{figure}

\subsection{Nvidia DLSS}
DLSS (\textit{Deep Learning SuperSampling}) Es un tipo de técnica de 
renderizado de video que busca aumentar la velocidad de cuadros por
segundo, renderizando cuadros a una resolución más baja que la mostrada.

El \textit{SuperSampling} hace
referencia a un metodo \textit{anti-aliasing} que suaviza los bordes 
irregulares que aparecen en los gráficos renderizados. 
Sin embargo, a diferencia de otras formas de anti-aliasing, 
SSAA (\textit{supersampling anti-aliasing}) funciona renderizando la imagen 
a una resolución mucho más alta y usando esos datos para llenar 
los espacios en la resolución nativa. \cite{ej-dlss}



DLSS es el resultado de un proceso exhaustivo de enseñanza del algoritmo
de inteligencia artificial de Nvidia para generar juegos más atractivos.
Después de renderizar el juego a una resolución más baja, 
DLSS infiere información de su base de conocimientos de entrenamiento 
de imágenes de superresolución para generar una imagen que todavía 
parece estar ejecutándose a una resolución más alta. 
La idea es hacer que los juegos renderizados a 1440p parezcan 
ejecutarse en 4K o que los juegos a 1080p parezcan 1440p. \cite{ej-dlss}

\subsubsection{¿Como funciona?}
La NN recibe dos entradas: 
\begin{itemize}
    \item{Imagenes aliased de baja resolucion generadas por el motor del
    juego}
    \item{En baja resolucion, vectores de movimiento de las mismas imagenes,
    tambien generados por el motor del juego.}
\end{itemize}

En este enfoque, los vectores de movimiento sirven para indicar la dirección 
en la que los objetos de una escena se desplazan de un cuadro a otro. 
Estos vectores se aplican nuevamente a la salida de alta resolución 
del cuadro anterior para prever cómo se visualizará en el próximo cuadro. 
Este procedimiento se denomina "Retroalimentación Temporal" porque utiliza 
la información pasada para anticipar eventos futuros. 
En el transcurso del aprendizaje, la imagen generada se compara con una 
imagen pre-renderizada de alta calidad con resolución de 16k.
Las discrepancias entre estas dos imágenes se retroalimentan a la red neuronal 
para perfeccionar y optimizar sus resultados. \cite{ej-dlss2}

Este ciclo se repite innumerables veces en una supercomputadora de Nvidia. 
Una vez que el modelo produce imágenes de calidad satisfactoria, 
se distribuye a los usuarios a través de actualizaciones de controladores 
para sus tarjetas gráficas. \cite{ej-dlss2}

En pocas palabras podemos decir que es un proceso iterativo de entrenamiento, 
donde la historia de las imágenes y la retroalimentación constante impulsan 
la mejora continua del modelo, que luego se implementa en las tarjetas gráficas 
de los usuarios mediante actualizaciones de controladores. 

\begin{figure}
    \centering
    \includegraphics[scale=0.4]{dlss.jpg}
    \caption{Arquitectura de Nvidia DLSS 2.0 \cite{ej-dlss2}}
    \label{fig:arquitectura-dlss}
\end{figure}

A continuacion van ejemplos que muestran el impacto de dlss3 en los fps.

\begin{figure}
    \centering
    \includegraphics[scale=0.2]{ej1-dlss3.jpg}
    \caption{Impacto de DLSS3 en el juego Cyberpunk 2077 \cite{img1-dlss3}}
    \label{fig:ej1-dlss3}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.4]{ej2-dlss3.jpg}
    \caption{Impacto de DLSS3 en el juego Microsoft flight simulator
    \cite{img2-dlss3}}
    \label{fig:ej2-dlss3}
\end{figure}

\subsection{Ejemplo5}
\section{Conclusion}

\newpage
\printbibliography

\end{document}